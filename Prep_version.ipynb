{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "from torch.utils.data import Dataset, DataLoader\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "\r\n",
    "#device config\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "df = pd.read_csv(\"train.csv\")\r\n",
    "df_train = df.drop(\"date_time\",1)[:5001]\r\n",
    "scaler = StandardScaler()\r\n",
    "scaler = scaler.fit(df_train)\r\n",
    "df_train = scaler.transform(df_train) #df_train is shape 5000,11 and dtype float64"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df_train.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5001, 11)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "df_train[0:300,:].shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(300, 11)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#hyperparameters\r\n",
    "\r\n",
    "sequence_length = 30\r\n",
    "batch_size = 40\r\n",
    "learning_rate = 0.001\r\n",
    "input_size = 11\r\n",
    "hidden_size = 32\r\n",
    "output_size = 3\r\n",
    "num_epochs = 10"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "#RESHAPING the problem to supervised learning\r\n",
    "#X shape --> (length-sequence_length),sequence_length,features 4700,300,11\r\n",
    "#y shape --> )length-sequence_length),targets 4700,11\r\n",
    "\r\n",
    "class Train_Time_Series_Dataset(Dataset):\r\n",
    "    def __init__(self, complete_data,sequence_length):\r\n",
    "        X, y = list(), list()\r\n",
    "        for i in range(len(complete_data)):\r\n",
    "            end_idx = i + sequence_length\r\n",
    "            if end_idx > len(complete_data) - 1:\r\n",
    "                break\r\n",
    "                \r\n",
    "            #seq_x shape --> sequence_length, features (for time steps up to t-1)\r\n",
    "            #seq_y shape --> targets (for time step t)\r\n",
    "            seq_x, seq_y = complete_data[i:end_idx,:], complete_data[end_idx,8:]\r\n",
    "            X.append(seq_x)\r\n",
    "            y.append(seq_y)\r\n",
    "        X = np.asarray(X, dtype=np.float32)\r\n",
    "        y = np.asarray(y, dtype=np.float32)\r\n",
    "        \r\n",
    "        self.X = torch.from_numpy(X)\r\n",
    "        self.y = torch.from_numpy(y)\r\n",
    "        self.sequence_length = sequence_length\r\n",
    "        self.n_samples = X.shape[0]\r\n",
    "        \r\n",
    "    def __getitem__(self,index):\r\n",
    "        return self.X[index], self.y[index]\r\n",
    "        \r\n",
    "    def __len__(self):\r\n",
    "        return self.n_samples\r\n",
    "\r\n",
    "class Eval_Dataset(Dataset):\r\n",
    "    def __init__(self,sequence):\r\n",
    "        self.X = torch.from_numpy(sequence)\r\n",
    "        self.n_samples = sequence.shape[0]\r\n",
    "    \r\n",
    "    def __getitem__(self, index):\r\n",
    "        return self.X[index]\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return self.n_samples\r\n",
    "\r\n",
    "dataset = Train_Time_Series_Dataset(df_train, sequence_length)\r\n",
    "train_loader = DataLoader(dataset=dataset,batch_size=batch_size,shuffle=True)\r\n",
    "eval_dataset = Eval_Dataset(df_train)  "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "#testing\r\n",
    "dataiter = iter(train_loader)\r\n",
    "sample_data =dataiter.next()\r\n",
    "#s_features shape --> batch_size, sequence_length, features\r\n",
    "#s_targets shape --> batch_size, targets\r\n",
    "s_features, s_targets = sample_data\r\n",
    "s_features = s_features.to(device)\r\n",
    "#s_targets = s_targets.to(device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "#DO NOT CONFUSE Hidden state with Weight matrix!\r\n",
    "\r\n",
    "class RNN(nn.Module):\r\n",
    "    def __init__(self,n_features,n_layers,hidden_size,output_size):\r\n",
    "        super(RNN,self).__init__()\r\n",
    "        self.n_layers = n_layers\r\n",
    "        self.hidden_size = hidden_size\r\n",
    "        self.rnn = nn.RNN(n_features, hidden_size,n_layers,batch_first=True)\r\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\r\n",
    "    \r\n",
    "    def forward(self,x):\r\n",
    "        h0 = torch.zeros(self.n_layers,x.size(0),self.hidden_size).to(device) #h0 shape --> n_layers, batch_size, hidden_size\r\n",
    "        out, _ = self.rnn(x, h0) #returns hidden states for all t\r\n",
    "        out = out[:,-1,:]\r\n",
    "        out = self.fc(out) #out shape --> batch_size, output_size\r\n",
    "        return out\r\n",
    "    \"\"\"\r\n",
    "    def predict(self,complete_sequence, starting_point, future):\r\n",
    "        #x shape --> batch_size, sequence_length,features = 1, 30, 11\r\n",
    "        x = complete_sequence[starting_point-sequence_length:starting_point]\r\n",
    "        x = torch.reshape(x,(1,-1,11)) #-1 is gonna be the sequence length\r\n",
    "        \r\n",
    "        \r\n",
    "        outputs = []\r\n",
    "        for i in range(future):\r\n",
    "            h0 = torch.zeros(self.n_layers,1,self.hidden_size).to(device)\r\n",
    "            _, h_f = self.rnn(x, h0)\r\n",
    "            out = self.fc(h_f)\r\n",
    "            outputs.append(out)\r\n",
    "            \r\n",
    "    \"\"\"\r\n",
    "    \r\n",
    "model = RNN(input_size,3,hidden_size,output_size).to(device)\r\n",
    "#loss and Optimizer\r\n",
    "criterion = nn.MSELoss()\r\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "outs = model(s_features)\r\n",
    "outs = torch.reshape(outs,(1,80,3))\r\n",
    "outs[0][2]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([ 0.1580, -0.1425, -0.3136], device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "x=eval_dataset[470:500]\r\n",
    "x=torch.reshape(x,(1,-1,11)).to(device)\r\n",
    "x=torch.roll(x,-1,1)\r\n",
    "new_t = torch.cat((x[0,29,:8],outs[0,2,:]),-1)\r\n",
    "x[:,-1]=new_t"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "#training loop\r\n",
    "n_total_steps = len(train_loader)\r\n",
    "\r\n",
    "running_loss = 0.0\r\n",
    "running_correct = 0\r\n",
    "\r\n",
    "#TRAIN\r\n",
    "for epoch in range(num_epochs):\r\n",
    "    for i, (features,targets) in enumerate(train_loader): #enumerate DataLoader\r\n",
    "        #features shape --> batch_size, sequence_length, features\r\n",
    "        #targets shape --> batch_size, targets\r\n",
    "        features = features.to(device)\r\n",
    "        targets = targets.to(device)\r\n",
    "        \r\n",
    "        #forward\r\n",
    "        outputs = model(features)\r\n",
    "        loss = criterion(outputs, targets)\r\n",
    "\r\n",
    "        #backward\r\n",
    "        optimizer.zero_grad()\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "\r\n",
    "        running_loss+= loss.item() #item returns a number\r\n",
    "\r\n",
    "        if (i+1) % 30 == 0:\r\n",
    "            print(f'epoch {epoch+1} / {num_epochs}, step {i+1} / {n_total_steps}, loss = {loss.item()}')\r\n",
    "            running_loss = 0.0\r\n",
    "\r\n",
    "\r\n",
    "#torch.save(model.state_dict(),\"mymodel.pth\")\r\n",
    "\r\n",
    "s_features = s_features.to(device)\r\n",
    "output = model(s_features)\r\n",
    "print(s_features.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 / 10, step 30 / 63, loss = 0.5646951794624329\n",
      "epoch 1 / 10, step 60 / 63, loss = 0.3374408483505249\n",
      "epoch 2 / 10, step 30 / 63, loss = 0.47250667214393616\n",
      "epoch 2 / 10, step 60 / 63, loss = 0.26771101355552673\n",
      "epoch 3 / 10, step 30 / 63, loss = 0.25746119022369385\n",
      "epoch 3 / 10, step 60 / 63, loss = 0.24269142746925354\n",
      "epoch 4 / 10, step 30 / 63, loss = 0.18945883214473724\n",
      "epoch 4 / 10, step 60 / 63, loss = 0.2444913685321808\n",
      "epoch 5 / 10, step 30 / 63, loss = 0.2582503855228424\n",
      "epoch 5 / 10, step 60 / 63, loss = 0.265308141708374\n",
      "epoch 6 / 10, step 30 / 63, loss = 0.13783381879329681\n",
      "epoch 6 / 10, step 60 / 63, loss = 0.18870976567268372\n",
      "epoch 7 / 10, step 30 / 63, loss = 0.1944522261619568\n",
      "epoch 7 / 10, step 60 / 63, loss = 0.13871189951896667\n",
      "epoch 8 / 10, step 30 / 63, loss = 0.23154489696025848\n",
      "epoch 8 / 10, step 60 / 63, loss = 0.20660722255706787\n",
      "epoch 9 / 10, step 30 / 63, loss = 0.1916838139295578\n",
      "epoch 9 / 10, step 60 / 63, loss = 0.18601341545581818\n",
      "epoch 10 / 10, step 30 / 63, loss = 0.1862940788269043\n",
      "epoch 10 / 10, step 60 / 63, loss = 0.19943860173225403\n",
      "torch.Size([80, 30, 11])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "#test\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "interpreter": {
   "hash": "920e380cd58ff3f8c2b75bf9efcc96d0d308e621547ab29c8c584eb095f03f01"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}